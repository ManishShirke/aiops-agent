# aiops-agent
ğŸ¤– Autonomous AI Ops Engineer (Capstone Project) using the AI Operator Pattern and Gemini Flash
Enterprise Agents Track â€” 5-Day AI Agents Intensive (Google)
A multi-agent system that observes, diagnoses, and resolves infrastructure incidents with human-in-the-loop safety.
 
ğŸ“– Project Overview
Modern infrastructure is becoming too complex for manual management, yet traditional automation scripts are too brittle to handle "unknown unknowns."
This Capstone project implements an Autonomous AI Ops Engineer. Unlike standard chatbots, this is an agentic system that utilizes the AI Operator Pattern. It actively monitors simulated infrastructure, uses Retrieval Augmented Generation (RAG) to recall historical fixes, and executes remediation tools (like kubectl scale) to resolve incidents.
Crucially, it solves the "Runaway AI" problem by implementing a strict Human-in-the-Loop (HITL) safety gate, ensuring no destructive action occurs without engineer approval.
 
ğŸ—ï¸ Architecture
The system is architected as a modular, event-driven Python application, decoupling the cognitive logic (Brain) from the infrastructure execution (Hands).

![Architecture Diagram](./aiops_architecture_bold.png)
 
Key Components
1.	Orchestrator: A finite state machine managing the lifecycle (Monitor â†’ Diagnose â†’ Remediate â†’ Verify).
2.	Gemini Adapter: The interface to Google Gemini 2.5 Flash-Lite, handling prompt engineering and safety interception.
3.	State Store (SQLite): Persistent memory for short-term facts and long-term RAG history.
4.	Observability Engine: A custom telemetry system tracking Traces, Spans, Latency, and Token Costs.
5.	Tools Layer: Simulated infrastructure tools (restart_service, scale_pods) executing via dynamic dispatch.
â€ƒ
 
âœ¨ Key Features
Feature	Description
ğŸ§  Cognitive Reasoning	Uses LLMs to diagnose root causes rather than matching regex patterns.
ğŸ“š RAG Memory	Queries SQLite to find how similar incidents were fixed in the past (e.g., "Scaling fixed latency in Jan").
ğŸ›¡ï¸ Safety Gate (HITL)	Pauses execution before running destructive tools (restart, scale) to wait for human Y/N  approval.
ğŸ“‰ Context Compaction	Automatically summarizes old incident logs when memory limits are reached to prevent context overflow.
ğŸ“Š SRE Observability	Generates distributed traces and a performance dashboard (Latency & Cost) for every run.


 
ğŸ“‚ Repository Structure
aiops_agent/
â”‚
â”œâ”€â”€ main.py                    # Entry point; handles seeding and execution loop
â”œâ”€â”€ config.py                  # Configuration (Models, DB paths)
â”‚
â”œâ”€â”€ orchestrator/              # THE BRAIN
â”‚   â””â”€â”€ ops_orchestrator.py    # Managing the multi-agent control loop
â”‚
â”œâ”€â”€ adapters/                  # THE INTERFACE
â”‚   â””â”€â”€ gemini_adapter.py      # Connects logic to LLM; Handles Safety & Tools
â”‚
â”œâ”€â”€ infrastructure/            # THE BACKEND
â”‚   â”œâ”€â”€ message_bus.py         # In-memory Pub/Sub for agent communication
â”‚   â””â”€â”€ state_store.py         # SQLite database & Compaction logic
â”‚
â”œâ”€â”€ observability/             # THE EYES
â”‚   â””â”€â”€ engine.py              # Telemetry, Spans, and Dashboard generation
â”‚
â”œâ”€â”€ prompts/                   # THE INSTRUCTIONS
â”‚   â””â”€â”€ agent_prompts.py       # System prompts with negative constraints
â”‚
â””â”€â”€ tools/                     # THE HANDS
    â””â”€â”€ actions.py             # Tool implementation logic
    

 
ğŸš€ Getting Started
Prerequisites
â€¢	Python 3.11+
â€¢	Google Gemini API Key

Installation
1.	Clone the repository
   
        Bash
  	
        git clone https://github.com/ManishShirke/aiops-agent.git
  	
        cd aiops-agent

3.	Install Dependencies
   
        Bash
  	
        pip install -q -U google-generativeai nest_asyncio

4.	Set API Key
	
        Bash
  	
        export GOOGLE_API_KEY="your_actual_api_key_here"

6. Running the Agent

   Execute the main script to start the simulation:
   
        Bash
   
        python aiops_agent/main.py
 
 
ğŸ¬ Demo Scenario
When you run the agent, the following scenario occurs automatically:
1.	Trigger: The system simulates an alert: "payments-api experiencing latency spikes."
2.	Diagnosis: The Agent searches memory, finds that scaling pods fixed this issue previously.
3.	Plan: It proposes a plan: ["scale_pods"].
4.	Intervention:
o	The system PAUSES and displays:
o	âš ï¸ [APPROVAL REQUIRED] Agent wants to execute: 'scale_pods'
5.	Action: You type y (or create an approval file).
6.	Resolution: The tool executes, the system verifies the fix, and archives the result.
7.	Dashboard: A full telemetry report is printed showing latency and costs.
 
ğŸ”® Future Roadmap
If this project were moved to production, the following enhancements would be prioritized:
1.	ChatOps Integration: Replace console input with a Slack Bot for collaborative team approvals.
2.	Vector Database: Migrate from SQLite keyword search to ChromaDB for semantic RAG (matching "slow" to "latency").
3.	Microservices: Dockerize the agents to run on Kubernetes with Prometheus triggers.
4.	Critic Agent: Add a secondary LLM to review plans against policy documents (e.g., "No restarts on Fridays") before human review.
 
ğŸ‘¨â€ğŸ’» Author
Manish Shirke
Capstone Project - Autonomous AI Ops Engineer
Course: Google 5-Day AI Agents Intensive




